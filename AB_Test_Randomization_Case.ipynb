{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AB_Test_Randomization_Case\n",
    "## Hao Wu\n",
    "## Description\n",
    "Channel KLMN is based in Los Angeles and airs a weekly national political talk show creatively called “US Politics This Week”. Their only TV commercial advertising “US Politics This Week” features the Mayor of Los Angeles. A data scientist at Channel KLMN found that a large fraction of people who saw the commercial for “US Politics This Week” and watched the show are from Los Angeles, while a much lower fraction of people from other cities who saw the commercial watched the show. They then brought this to the attention of the team that produces “US Politics This Week”.\n",
    "\n",
    "The Executive Producer of “US Politics This Week” suggested that they make TV commercials tailored to some of the biggest cities in the US that feature the Mayors of those cities (i.e., a commercial to be shown in New York City that features the Mayor of New York City, a commercial to be shown in Chicago that features the Mayor of Chicago, etc.). Channel KLMN decided to produce these new commercials and then aired the new commercials in their respective cities, in addition to airing the old commercial (featuring the Mayor of Los Angeles) in all cities as well.\n",
    "\n",
    "After running the experiment, the data scientist was surprised to find that the test is negative. That is, a lower fraction of people who saw the commercials with their local Mayor watched “US Politics This Week” as compared to people who saw the commercial with the Mayor of Los Angeles!\n",
    "### Your job is to:\n",
    "* Reproduce the negative result found above. Is it actually negative?\n",
    "* Explain what might be happening. Are the commercials with local Mayors really driving a lower fraction of people to watch the show?\n",
    "* If you found something wrong with the experiment, design an algorithm that returns FALSE if the problem happens again in the future and TRUE if everything is good and the results can be trusted. If you didn’t find anything wrong with the experiment, what is your recommendation to the Executive Producer of “US Politics This Week” regarding whether or not they should continue airing the new commercials?\n",
    "### Data:\n",
    "#### test_data:\n",
    "* viewer_id: the ID of the viewer\n",
    "* date: the date the viewer saw a commercial for “US Politics This Week”\n",
    "* tv_make: the make (i.e., brand) of TV\n",
    "* tv_size: the size of the TV in inches (approximately measured as the diagonal of the screen)\n",
    "* uhd_capable: whether the TV is (1) or is not (0) capable of displaying Ultra-High-Definition television content\n",
    "* tv_provider: the cable or satellite TV provider\n",
    "* total_time_watched: the total amount of TV watched (in hours) on the day in the ‘date’ column\n",
    "* watched: whether the viewer watched (1) “US Politics This Week” or not (0)\n",
    "* test: viewers are split into test (1) and control (0) groups; test viewers saw the new commercial with their local Mayor while control viewers saw the old commercial with the Mayor of Los Angeles\n",
    "#### viewer_data columns:\n",
    "* viewer_id: the ID of the viewer; same ID as in the test_data file\n",
    "* gender: the viewer’s gender\n",
    "* age: the viewer’s age\n",
    "* city: the viewer’s city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewer table\n",
      "   viewer_id  gender  age      city\n",
      "0    1918165  Female   39    Dallas\n",
      "1   27662619  Female   28  New York\n",
      "2    5493662  Female   53   Detroit\n",
      "3   14441247    Male   41  New York\n",
      "4   25595927    Male   53   Seattle\n",
      "test table\n",
      "   viewer_id        date tv_make  tv_size  uhd_capable   tv_provider  \\\n",
      "0   24726768  2018-01-16    Sony       70            0       Comcast   \n",
      "1   25001464  2018-01-18    Sony       32            0           NaN   \n",
      "2   28291998  2018-01-18    Sony       50            1  Dish Network   \n",
      "3   17057157  2018-01-19    Sony       32            0       Comcast   \n",
      "4   29504447  2018-01-17    Sony       32            0       Comcast   \n",
      "\n",
      "   total_time_watched  watched  test  \n",
      "0               10.75        0     1  \n",
      "1                2.75        0     0  \n",
      "2               20.00        0     0  \n",
      "3                1.50        0     0  \n",
      "4               17.50        0     0  \n"
     ]
    }
   ],
   "source": [
    "#Input data and basic check\n",
    "viewer=pd.read_csv(\"/Users/haowu/Google Drive/Data Science/takehome/Samba_TV/viewer_data.csv\")\n",
    "test=pd.read_csv(\"/Users/haowu/Google Drive/Data Science/takehome/Samba_TV/test_data.csv\")\n",
    "print(\"viewer table\")\n",
    "print(viewer.head())\n",
    "print(\"test table\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "556\n"
     ]
    }
   ],
   "source": [
    "#check users in two table\n",
    "print(len(viewer.viewer_id.unique())==len(viewer)) #check if the viewer table is unique at viewer_id level\n",
    "print(len(test.viewer_id.unique())==len(test)) #check if the test table is unique at viewer_id level\n",
    "print(len(test.viewer_id.unique())-len(viewer.viewer_id.unique())) #check if two tables are 1-to-1 match on the reviewer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewer table information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.174640e+05</td>\n",
       "      <td>417464</td>\n",
       "      <td>417464.000000</td>\n",
       "      <td>417464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>209416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.837908e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.473298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.247548e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.056198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.571130e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.841588e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.917900e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.999992e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           viewer_id  gender            age      city\n",
       "count   4.174640e+05  417464  417464.000000    417464\n",
       "unique           NaN       2            NaN        15\n",
       "top              NaN  Female            NaN  New York\n",
       "freq             NaN  209416            NaN     69893\n",
       "mean    1.837908e+07     NaN      40.473298       NaN\n",
       "std     1.247548e+07     NaN      12.056198       NaN\n",
       "min     1.000000e+04     NaN      18.000000       NaN\n",
       "25%     7.571130e+06     NaN      31.000000       NaN\n",
       "50%     1.841588e+07     NaN      39.000000       NaN\n",
       "75%     2.917900e+07     NaN      48.000000       NaN\n",
       "max     3.999992e+07     NaN      74.000000       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"viewer table information\")\n",
    "viewer.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test table information\n",
      "           viewer_id        date tv_make        tv_size    uhd_capable  \\\n",
      "count   4.180260e+05      418026  418026  418026.000000  418026.000000   \n",
      "unique           NaN           5       4            NaN            NaN   \n",
      "top              NaN  2018-01-15    Sony            NaN            NaN   \n",
      "freq             NaN       86641  271922            NaN            NaN   \n",
      "mean    1.835585e+07         NaN     NaN      51.874111       0.200858   \n",
      "std     1.248317e+07         NaN     NaN      12.225413       0.400643   \n",
      "min     1.000000e+04         NaN     NaN      32.000000       0.000000   \n",
      "25%     7.526723e+06         NaN     NaN      40.000000       0.000000   \n",
      "50%     1.838327e+07         NaN     NaN      55.000000       0.000000   \n",
      "75%     2.916353e+07         NaN     NaN      65.000000       0.000000   \n",
      "max     3.999992e+07         NaN     NaN      70.000000       1.000000   \n",
      "\n",
      "       tv_provider  total_time_watched        watched           test  \n",
      "count       365306       418026.000000  418026.000000  418026.000000  \n",
      "unique           5                 NaN            NaN            NaN  \n",
      "top        Comcast                 NaN            NaN            NaN  \n",
      "freq        109796                 NaN            NaN            NaN  \n",
      "mean           NaN           10.039700       0.054547       0.488790  \n",
      "std            NaN            6.179722       0.227094       0.499875  \n",
      "min            NaN            0.250000       0.000000       0.000000  \n",
      "25%            NaN            5.000000       0.000000       0.000000  \n",
      "50%            NaN            9.500000       0.000000       0.000000  \n",
      "75%            NaN           14.500000       0.000000       1.000000  \n",
      "max            NaN           23.750000       1.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"test table information\")\n",
    "print(test.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight and Action\n",
    "As we can see the viewer table includes the unique viewer information, and in the test table, one viewer might have multiple actions. And some viewers in the test table do not have information in the viewer table. For the further analysis, I will combine two tables together by keeping all users in the test table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418026, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tv_make</th>\n",
       "      <th>tv_size</th>\n",
       "      <th>uhd_capable</th>\n",
       "      <th>tv_provider</th>\n",
       "      <th>total_time_watched</th>\n",
       "      <th>watched</th>\n",
       "      <th>test</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.180260e+05</td>\n",
       "      <td>418026</td>\n",
       "      <td>418026</td>\n",
       "      <td>418026.000000</td>\n",
       "      <td>418026.000000</td>\n",
       "      <td>365306</td>\n",
       "      <td>418026.000000</td>\n",
       "      <td>418026.000000</td>\n",
       "      <td>418026.000000</td>\n",
       "      <td>417470</td>\n",
       "      <td>417470.000000</td>\n",
       "      <td>417470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>Sony</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>86641</td>\n",
       "      <td>271922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.835585e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.874111</td>\n",
       "      <td>0.200858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.039700</td>\n",
       "      <td>0.054547</td>\n",
       "      <td>0.488790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.473234</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.248317e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.225413</td>\n",
       "      <td>0.400643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.179722</td>\n",
       "      <td>0.227094</td>\n",
       "      <td>0.499875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.056215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.526723e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.838327e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.916353e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.999992e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           viewer_id        date tv_make        tv_size    uhd_capable  \\\n",
       "count   4.180260e+05      418026  418026  418026.000000  418026.000000   \n",
       "unique           NaN           5       4            NaN            NaN   \n",
       "top              NaN  2018-01-15    Sony            NaN            NaN   \n",
       "freq             NaN       86641  271922            NaN            NaN   \n",
       "mean    1.835585e+07         NaN     NaN      51.874111       0.200858   \n",
       "std     1.248317e+07         NaN     NaN      12.225413       0.400643   \n",
       "min     1.000000e+04         NaN     NaN      32.000000       0.000000   \n",
       "25%     7.526723e+06         NaN     NaN      40.000000       0.000000   \n",
       "50%     1.838327e+07         NaN     NaN      55.000000       0.000000   \n",
       "75%     2.916353e+07         NaN     NaN      65.000000       0.000000   \n",
       "max     3.999992e+07         NaN     NaN      70.000000       1.000000   \n",
       "\n",
       "       tv_provider  total_time_watched        watched           test  gender  \\\n",
       "count       365306       418026.000000  418026.000000  418026.000000  417470   \n",
       "unique           5                 NaN            NaN            NaN       2   \n",
       "top        Comcast                 NaN            NaN            NaN  Female   \n",
       "freq        109796                 NaN            NaN            NaN  209420   \n",
       "mean           NaN           10.039700       0.054547       0.488790     NaN   \n",
       "std            NaN            6.179722       0.227094       0.499875     NaN   \n",
       "min            NaN            0.250000       0.000000       0.000000     NaN   \n",
       "25%            NaN            5.000000       0.000000       0.000000     NaN   \n",
       "50%            NaN            9.500000       0.000000       0.000000     NaN   \n",
       "75%            NaN           14.500000       0.000000       1.000000     NaN   \n",
       "max            NaN           23.750000       1.000000       1.000000     NaN   \n",
       "\n",
       "                  age      city  \n",
       "count   417470.000000    417470  \n",
       "unique            NaN        15  \n",
       "top               NaN  New York  \n",
       "freq              NaN     69894  \n",
       "mean        40.473234       NaN  \n",
       "std         12.056215       NaN  \n",
       "min         18.000000       NaN  \n",
       "25%         31.000000       NaN  \n",
       "50%         39.000000       NaN  \n",
       "75%         48.000000       NaN  \n",
       "max         74.000000       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=test.merge(viewer,on=\"viewer_id\",how=\"left\")\n",
    "print(data.shape)\n",
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Replicate A/B Test Result\n",
    "I will remove the Los Angeles data in the test table, because based on the information, the commercial will not change in the LA area. Therefore, there is no experiment there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a test function presenting the T test result\n",
    "def test_result(df,label,group_var='test'):\n",
    "    \n",
    "    test = stats.ttest_ind(df.loc[df[group_var] == 1,label], \n",
    "                           df.loc[df[group_var] == 0,label], \n",
    "                       equal_var=False)\n",
    "  \n",
    "    print(\"statistics\")\n",
    "    print(test.statistic)\n",
    "    print(\" \")\n",
    "    print(\"p-value\")\n",
    "    print(test.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365513, 12)\n",
      "test control group size compare 0.5590143168642429 0.44098568313575714\n"
     ]
    }
   ],
   "source": [
    "test_data=data.loc[data.city!=\"Los Angeles\"]\n",
    "print(test_data.shape)\n",
    "#Make sure the test and control are correctly split. \n",
    "print(\"test control group size compare\",sum(test_data.test==1)/len(test_data),sum(test_data.test==0)/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.559014\n",
       "0    0.440986\n",
       "Name: test, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the overall test and control group assignment\n",
    "test_data.test.value_counts()/len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics\n",
      "-5.720411142093989\n",
      " \n",
      "p-value\n",
      "1.0635551786694859e-08\n"
     ]
    }
   ],
   "source": [
    "test_result(test_data,label=\"watched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the test and control groups are evenly split. As we can see the watch rate in the test group is 4.58%, and the control group is 4.99%, and the test group is lower by 9%.  This result is not as expected. I will use statistical analysis to check two check following two parts: \n",
    "   * Was the experiment set up correctly, i.e. were test/group viewers are ramdonly selected in different segment.\n",
    "\n",
    "\n",
    "# Step 2 Identify the Potential Reasons\n",
    "\n",
    "**Actions** define a function applying the DT model to check if the users are fully randomly assigned. the feature importance will output. If the the randomization is correctly implemented, the feature importance of all segments should be low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_detect(df,segment_var):       \n",
    "    model_data=pd.get_dummies(df[segment_var]).fillna(0)\n",
    "    model=DecisionTreeClassifier(class_weight=\"balanced\",min_impurity_decrease = 0.001)\n",
    "    model.fit(model_data,df[\"test\"])\n",
    "    fi = pd.DataFrame({'feature': model_data.columns,\n",
    "                       'importance': model.feature_importances_}).sort_values('importance', ascending = False)\n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the original data\n",
    "#because the total_time_watched could not be practical in the user segements, so drop it out. \n",
    "f_im=feature_importance_detect(test_data,\n",
    "                               ['tv_make','tv_size','tv_provider','gender','age','city','uhd_capable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>city_Philadelphia</td>\n",
       "      <td>0.581394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>city_Seattle</td>\n",
       "      <td>0.418606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance\n",
       "23  city_Philadelphia    0.581394\n",
       "26       city_Seattle    0.418606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list out the segmentation vars over the threshold of feature importance\n",
    "f_im.loc[~(abs(f_im['importance']-0)<1e-06)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>group_count</th>\n",
       "      <th>total_group_count</th>\n",
       "      <th>percent</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>4261</td>\n",
       "      <td>213699</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>24495</td>\n",
       "      <td>204327</td>\n",
       "      <td>0.119881</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>2846</td>\n",
       "      <td>213699</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>15850</td>\n",
       "      <td>204327</td>\n",
       "      <td>0.077572</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city  group_count  total_group_count   percent    group\n",
       "0  Philadelphia         4261             213699  0.019939  Control\n",
       "1  Philadelphia        24495             204327  0.119881     Test\n",
       "0       Seattle         2846             213699  0.013318  Control\n",
       "1       Seattle        15850             204327  0.077572     Test"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Present the test/control group ratios to confirm the model output\n",
    "msk=test_data.city.isin([\"Philadelphia\",\"Seattle\"])\n",
    "grp=test_data.loc[msk].groupby(\"city\")[\"test\"].agg(['value_counts'])\n",
    "grp=grp.reset_index(\"city\").join(data.test.value_counts())\n",
    "grp.columns=[\"city\",'group_count',\"total_group_count\"]\n",
    "grp[\"percent\"]=grp[\"group_count\"]/grp[\"total_group_count\"]\n",
    "grp[\"group\"]=np.where(grp.index==0,\"Control\",\"Test\")\n",
    "grp.sort_values(by='city')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights\n",
    "Randomization works good in the groups of tv providers and tv makers, because the ratios of control to test are very statble. However, we do see the outiliers in the city group, which are Philadelphia and Seattle, which means, most viewers are assgined in the test groups. \n",
    "\n",
    "# Actions\n",
    "Will Increase the weight of users from Philadelphia and Seattle in the control group so that they are perfectly balanced between the two groups. \n",
    "\n",
    "\n",
    "* Figure out how many new rows having test = 0 and city = Philadelphia or Seattle you would need to add to the original dataset to balance the relative frequencies\n",
    "\n",
    "* Randomly sample from the original dataset those rows and append them to the dataset\n",
    "\n",
    "* Check that the proportion of users from those two cities is now the same for test and control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Seattle': 5.824667008126684, 'Philadelphia': 6.012327662070761}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the test/control group ratio to calculate the resampling size. \n",
    "sample_dict=dict()\n",
    "sample_dict={i: grp.loc[(grp.group=='Test') & (grp[\"city\"]==i) ,'percent'].values[0]\\\n",
    "             /grp.loc[(grp.group=='Control') & (grp[\"city\"]==i) , 'percent'].values[0]\n",
    "                        for i in set(grp[\"city\"])}\n",
    "sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16577, 12)\n",
      "(25619, 12)\n"
     ]
    }
   ],
   "source": [
    "#Here we will use the oversampling approach, so will resample the control groups of AR and UR with replacement. \n",
    "over_sample_data=[test_data]\n",
    "\n",
    "for c in sample_dict.keys():\n",
    "    sub_df=test_data.loc[(test_data.city==c)&(test_data.test==0)]\n",
    "    sub_df=sub_df.sample(frac=sample_dict[c], \n",
    "                         replace=True, random_state=1)\n",
    "    print(sub_df.shape)\n",
    "    over_sample_data.append(sub_df)\n",
    "over_sample_data=pd.concat(over_sample_data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>group_count</th>\n",
       "      <th>total_group_count</th>\n",
       "      <th>percent</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>29880</td>\n",
       "      <td>203382</td>\n",
       "      <td>0.146916</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>24495</td>\n",
       "      <td>204327</td>\n",
       "      <td>0.119881</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>19423</td>\n",
       "      <td>203382</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>15850</td>\n",
       "      <td>204327</td>\n",
       "      <td>0.077572</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city  group_count  total_group_count   percent    group\n",
       "0  Philadelphia        29880             203382  0.146916  Control\n",
       "1  Philadelphia        24495             204327  0.119881     Test\n",
       "0       Seattle        19423             203382  0.095500  Control\n",
       "1       Seattle        15850             204327  0.077572     Test"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recheck the test/control groups of those two cities\n",
    "msk=over_sample_data.city.isin([\"Philadelphia\",\"Seattle\"])\n",
    "grp=over_sample_data.loc[msk].groupby(\"city\")[\"test\"].agg(['value_counts'])\n",
    "grp=grp.reset_index(\"city\").join(over_sample_data.test.value_counts())\n",
    "grp.columns=[\"city\",'group_count',\"total_group_count\"]\n",
    "grp[\"percent\"]=grp[\"group_count\"]/grp[\"total_group_count\"]\n",
    "grp[\"group\"]=np.where(grp.index==0,\"Control\",\"Test\")\n",
    "grp.sort_values(by='city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature, importance]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To make sure the resampling doesn't cause the inbalances among other segments, do the Decesion Tree check again\n",
    "resample_f_im=feature_importance_detect(over_sample_data,\n",
    "                               ['tv_make','tv_size','tv_provider','gender','age','city','uhd_capable'])\n",
    "#check if there is any features having significant importance. We can see no feature has significance in the group\n",
    "#allocation. \n",
    "resample_f_im.loc[~(abs(resample_f_im['importance']-0)<1e-06)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics\n",
      "1.5610131287673206\n",
      " \n",
      "p-value\n",
      "0.11852142940765997\n"
     ]
    }
   ],
   "source": [
    "#reproduce the test results\n",
    "test_result(over_sample_data,label='watched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "* As using the random sampling approaches, the unbalanced randomization was fixed. However the test result is not statistically significant, with p-value above 0.1. Therefore the experiment didn't improve the watch rate. If there is no other metrics to consider, I would not recommend to launch “US Politics This Week”  national wide. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[NbConvertApp] Converting notebook AB_Test_Randomization_Case.ipynb to html',\n",
       " '[NbConvertApp] Writing 339660 bytes to AB_Test_Randomization_Case.html']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!jupyter nbconvert *.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
